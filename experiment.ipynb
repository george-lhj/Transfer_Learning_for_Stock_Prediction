{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import iisignature\n",
    "from iisignature import sig, prepare, logsig, logsiglength\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Ridge, RidgeClassifier, LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet(\"./datasets/df_train_wdate_wclusters.parquet\")\n",
    "df_test = pd.read_parquet(\"./datasets/df_test_wdate_wclusters.parquet\")\n",
    "\n",
    "industry_lst = df_train.INDUSTRY.unique() # 'INDUSTRY'\n",
    "industry_group_lst = df_train.INDUSTRY_GROUP.unique() # 'INDUSTRY_GROUP'\n",
    "sector_lst = df_train.SECTOR.unique() # 'SECTOR'\n",
    "sub_industry_lst = df_train.SUB_INDUSTRY.unique() # 'SUB_INDUSTRY'\n",
    "stock_lst = df_train.STOCK.unique() # 'STOCK'\n",
    "cluster_lst = df_train.CLUSTER.unique() # 'CLUSTER'\n",
    "\n",
    "param_grid = {\n",
    "    \"C\": np.logspace(-3, 3, num=10)  # e.g., 0.001 to 1000\n",
    "}\n",
    "\n",
    "results = []\n",
    "y_true_all = []\n",
    "y_pred_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['CLUSTER'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47275a904878423ab27d9613c9650a79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing clusters:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping cluster 0 - no data.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------\n",
    "# 2) TRAIN AND EVALUATE PER CLUSTER\n",
    "# -----------------------------------------------------------------\n",
    "for cluster_idx in tqdm(cluster_lst, total=len(cluster_lst), desc=\"Processing clusters\"):\n",
    "    try:\n",
    "        # Split train/test data for this cluster\n",
    "        df_cluster_train = df_train[df_train[\"CLUSTER\"] == cluster_idx]\n",
    "        df_cluster_test  = df_test[df_test[\"CLUSTER\"] == cluster_idx]\n",
    "\n",
    "        # Skip cluster if no data in train or test\n",
    "        if len(df_cluster_train) == 0 or len(df_cluster_test) == 0:\n",
    "            print(f\"Skipping cluster {cluster_idx} - no data.\")\n",
    "            continue\n",
    "\n",
    "        # Identify feature columns (those starting with \"SIG_\")\n",
    "        feature_cols = [c for c in df_cluster_train.columns if c.startswith(\"SIG_\")]\n",
    "\n",
    "        # Extract X and y for training and testing\n",
    "        X_train = df_cluster_train[feature_cols].values\n",
    "        y_train = df_cluster_train[\"RET\"].values  # assume labels are 0/1\n",
    "        X_test = df_cluster_test[feature_cols].values\n",
    "        y_test = df_cluster_test[\"RET\"].values\n",
    "\n",
    "        # Skip cluster if X or y is empty (shouldn't happen, but safety check)\n",
    "        if X_train.shape[0] == 0 or X_test.shape[0] == 0:\n",
    "            print(f\"Skipping cluster {cluster_idx} - empty X or y.\")\n",
    "            continue\n",
    "\n",
    "        # Standardize features: fit on training data then transform both sets\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "        # Use GridSearchCV to tune LogisticRegression with L2 penalty (ridge logistic regression)\n",
    "        gs = GridSearchCV(\n",
    "            estimator=LogisticRegression(penalty=\"l2\", solver=\"liblinear\", max_iter=1000),\n",
    "            param_grid=param_grid,\n",
    "            cv=5,              # 5-fold cross-validation\n",
    "            scoring=\"accuracy\",\n",
    "            n_jobs=1\n",
    "        )\n",
    "        gs.fit(X_train_scaled, y_train)\n",
    "\n",
    "        # Extract the best hyperparameter and model\n",
    "        best_C = gs.best_params_[\"C\"]\n",
    "        best_model = gs.best_estimator_\n",
    "\n",
    "        # Get predicted probabilities for class 1 from the best model\n",
    "        y_val_proba = best_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "        # --- Custom Threshold: Compute the median of the predicted probabilities ---\n",
    "        custom_threshold = np.median(y_val_proba)\n",
    "        # Create custom predictions: assign 1 if probability >= median, else 0\n",
    "        y_val_pred_custom = (y_val_proba >= custom_threshold).astype(int)\n",
    "\n",
    "        # Get default predictions using the model's built-in threshold (0.5)\n",
    "        y_val_pred_default = best_model.predict(X_test_scaled)\n",
    "\n",
    "        # Evaluate default predictions\n",
    "        acc_default = accuracy_score(y_test, y_val_pred_default)\n",
    "        report_default = classification_report(y_test, y_val_pred_default, zero_division=0)\n",
    "\n",
    "        # Evaluate custom predictions (using median threshold)\n",
    "        acc_custom = accuracy_score(y_test, y_val_pred_custom)\n",
    "        report_custom = classification_report(y_test, y_val_pred_custom, zero_division=0)\n",
    "\n",
    "        # Aggregate default predictions for overall evaluation\n",
    "        y_true_all.extend(y_test)\n",
    "        y_pred_all.extend(y_val_pred_default)\n",
    "\n",
    "        # Save the results for this cluster\n",
    "        results.append({\n",
    "            \"Cluster\": cluster_idx,\n",
    "            \"Train_Samples\": len(df_cluster_train),\n",
    "            \"Test_Samples\": len(df_cluster_test),\n",
    "            \"Best_C\": best_C,\n",
    "            \"Default_Accuracy\": acc_default,\n",
    "            \"Custom_Accuracy\": acc_custom,\n",
    "            \"Default_Report\": report_default,\n",
    "            \"Custom_Report\": report_custom,\n",
    "            \"Custom_Threshold\": custom_threshold,\n",
    "            \"Model\": best_model\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing cluster {cluster_idx}: {e}\")\n",
    "        continue\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "# 3) SUMMARIZE RESULTS\n",
    "# -----------------------------------------------------------------\n",
    "df_results = pd.DataFrame(results)\n",
    "print(df_results[[\"Cluster\", \"Train_Samples\", \"Test_Samples\", \"Best_C\", \n",
    "                  \"Default_Accuracy\", \"Custom_Accuracy\", \"Custom_Threshold\"]])\n",
    "\n",
    "overall_accuracy = accuracy_score(y_true_all, y_pred_all)\n",
    "print(f\"\\nOverall Default Accuracy across all clusters: {overall_accuracy:.4f}\")\n",
    "\n",
    "# Optionally, you can inspect the classification reports:\n",
    "# for idx, row in df_results.iterrows():\n",
    "#     print(f\"\\nCluster {row['Cluster']} - Default Report:\")\n",
    "#     print(row['Default_Report'])\n",
    "#     print(f\"Cluster {row['Cluster']} - Custom Report:\")\n",
    "#     print(row['Custom_Report'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
